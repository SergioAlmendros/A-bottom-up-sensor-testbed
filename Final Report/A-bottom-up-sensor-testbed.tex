\documentclass[12pt, a4paper,twoside]{tesi_upf}

\usepackage{pgfgantt}
\usepackage{tikz}
\usepackage{eurosym}

\usetikzlibrary{shapes.geometric, arrows}

\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!30]

\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!30]

\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, text width=3cm, draw=black, fill=orange!30]

\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]

\tikzstyle{arrow} = [thick,->,>=stealth]

%CODIFICACIÓ
\usepackage[latin1]{inputenc}


%IDIOMES
\usepackage[catalan,english]{babel}

%NOMÉS PER A OBTENIR INDICACIÓ DEL MARC EN MIDA A4
%\usepackage[cam,a4,center,frame]{crop}

%PER A INCLOURE GRÀFICS I EL LOGO DE LA UPF
%\usepackage{graphicx}

\usepackage{caption}
\usepackage{subcaption}

\usepackage{graphicx}
\newsavebox\IBoxA \newsavebox\IBoxB \newlength\IHeight
\newcommand\TwoFig[6]{% Image1 Caption1 Label1 Image2 ...
  \sbox\IBoxA{\includegraphics[width=0.45\textwidth]{#1}}
  \sbox\IBoxB{\includegraphics[width=0.45\textwidth]{#4}}%
  \ifdim\ht\IBoxA>\ht\IBoxB
    \setlength\IHeight{\ht\IBoxB}\else\setlength\IHeight{\ht\IBoxA}\fi%
  \begin{figure}[htbp]
  \minipage[t]{0.45\textwidth}\centering
  \includegraphics[height=\IHeight]{#1}
  \rule{14em}{0.5pt}
  \caption{#2}\label{#3}
  \endminipage\hfill
  \minipage[t]{0.45\textwidth}\centering
  \includegraphics[height=\IHeight]{#4}
  \rule{14em}{0.5pt}
  \caption{#5}\label{#6}
  \endminipage 
  \end{figure}%
}

\usepackage{caption}
\usepackage{acronym}
\usepackage{multirow}
%FONTS TIMES O GARAMOND, 
\usepackage{times}
%\usepackage{garamond}
\usepackage{url}

\usepackage{pdfpages}
%SENSE HEADINGS: NO MODIFICAR
\pagestyle{plain}

%PER A L'ÍNDEX DE MATÈRIES
\usepackage{makeidx}
\makeindex

%ESTIL DE BIBLIOGRAFIA
\bibliographystyle{apalike}


%AQUEST DOCUMENT ÉS EN CATALÀ
\selectlanguage{english}

%EN COMPTES DE ÍNDEX, LA TAULA DE CONTINGUTS ES TITULA SUMARI
\addto\captionscatalan
  {\renewcommand{\contentsname}{\Large \sffamily Sumari}}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~
% CUSTOM PACKAGES
% ~~~~~~~~~~~~~~~~~~~~~~~~~~
%\usepackage{hyperref}
\usepackage[hidelinks]{hyperref}
\usepackage{titlesec}
\setcounter{secnumdepth}{4}
\usepackage{pdfpages}

%AFEGIU EN AQUESTA PART LES VOSTRES DADES
\title{A bottom up sensor testbed}
\author{Sergio Almendros Díaz}
\thyear{2014}
\department{Departament de Tecnologies de la Informació i les Comunicacions (DTIC)}
\supervisor{Jaume Barceló}


\begin{document}

\pdfstringdefDisableCommands{%
\let\MakeUppercase\relax
}

\frontmatter

\maketitle

\cleardoublepage


%%%%%% Dedicatòria; si no es vol posar, comenteu fins a final de dedicatòria

%\noindent Dedicatòria

%\cleardoublepage

%%%%%% Final de dedicatòria


%%%%%% Agraïments; si no es vol posar, comenteu fins a final de agraïments
\noindent {\Large \sffamily Acknowledgments}


\cleardoublepage

%%%%%% Final dels agraïments

%ABSTRACT EN DOS IDIOMES. COM A MÍNIM CATALÀ. SI L'ALTRE ÉS EN CASTELLA CANVIEU EL QUE POSA ABSTRACT
\selectlanguage{english}
\section*{\Large \sffamily Abstract}

  This project aims to deploy sensor node network into the guifi network, an open, free, and neutral network, and the visualization of this data in an intuitive way that helps final users to understand the meaning of these data without any previous scientific knowledge.
  
  The main objective is to give citizens environmental conscience so that they are aware of their surroundings and could act accordingly if anything stands.
  
  This way anybody can act consequently if the sensors detect harmful situations, such as, not going to a park where the gas sensor detects a bad air quality.
   
  From this point, arduino Yun is the best choice to be the main component of the sensor node, and through a series of sensors attached to it and the Internet connection that provides guifi, the node can communicate with a storage platform of sensor data, in this case, opencities. Finally, an android application downloads the sensor data from the servers of opencities and display them on a map.


\selectlanguage{catalan}
\vspace*{\fill}
\section*{\Large \sffamily  Resum}

Cuando el Abstract esté perfecto, lo traduciré al catalan.

\vspace*{\fill}

\selectlanguage{english}
\cleardoublepage
%FIN DE ABSTRACTE

%PREFACI OPCIONAL. SI NO ES VOL, COMENTEU FINS EL FINAL DE PREFACI
%{\bf Prefaci}
%
%\cleardoublepage
%FINAL DE PREFACI


%TAULA DE CONTINGUTS: OBLIGATÒRIA
\selectlanguage{english}
\tableofcontents

%INDEX DE FIGURES; NOMÉS ES POSA SI HI HA FIGURES
\listoffigures
%Fa que aparegui al sumari
\addcontentsline{toc}{chapter}{List of figures}

%INDEX DE TAULES; NOMÉS ES POSA SI HI HA TAULES
\listoftables
%Fa que aparegui al sumari
\addcontentsline{toc}{chapter}{List of tables}


%COMENÇA EL TEXT
\mainmatter
\chapter{Introduction}
\label{Chapter1}

  The development of this project involves two parts, collect sensor data and show it.

  A sensor testbed is a sensor network that has the goal to gather sensor data, and test the technologies used as nodes to see if they are the best option.

  Bottom-up\footnote{\url{http://bubforeurope.net}} is, basically, the pattern that we used to build the sensor testbed, where the end users, in this case, guifi.net users, are the ones who have to assemble the sensor nodes and attached them to their guifi nodes to create the sensor network. With the bottom-up model, the data is provide and use by the end users.
  This project is an easy way to understand the importance of sensor networks and how they can help us to know, for example, if there is low quality air in our city, and do something about it.

  As sensor nodes we will use an Arduino\cite{arduino} YUN, which allows the user to obtain analog reads from a sensor very easily and, with a Power over Ethernet module, it can be attached to guifi\footnote{\url{http://guifi.net/}} nodes and send the sensor data to a sensor platform, like opencities\cite{opencities}.

  The project will include an Android application to visualize this data and make it more accessible to other users not involved with guifi.net.

  In the following chapters it will be explain the state of sensor networks nowadays (Chapter \ref{Chapter2}), which technologies we will use (Chapter \ref{Chapter3}), and how the project has been done (Chapter \ref{Chapter4}). 

  Finally there will be the results (Chapter \ref{Chapter5}) of the testbed, and conclusions (Chapter \ref{Chapter6}) and future work (Chapter \ref{Chapter7}).
  
\chapter{State of the Art}
\label{Chapter2}
  
  \section{Introduction}
    Sensor networks started as a mecanism of defense developed by the military during the Cold War, with acoustic sensors they tried to find Soviet submarines. This search continued at universities, trying to make this sensors smaller, and with the posibility of real-time data\cite{chong2003sensor}.
    
    Right now, sensors are small enough, and processors with network technology have low energy consumption, which allows us to deploy a test bed without people notice it.
    
    Smart cities are the next step, a city capable of having real-time information, not only about the environment, it can go from the amount of cars that pass a road, to the amount of rain water in a day. This kind of information could help to manage more efficiently the city.
    
    It is important to share this information, in the case that the government build the sensor network, the data should be open to everyone could see it. There are already some sensor networks functioning, some of them are from the government, and, sometimes, there are not that open about their data, but there are also some people who have sensors nodes at home and share the information with everyone.

  \section{Sensor networks and smart cities}
    In this section we introduce a few projects of sensor networks deployed:
    
    \subsection{Amsterdam smart city}
      Amsterdam have a lot of projects concerning the smart city concept, like the ``Flexible street lighting'', which allows the government to monitor the street and switch off the lights to save energy, or the ``Smart parking'' which let drivers to know if there are free spots to park, and, in consecuence, reduce air pollution \cite{SmartcityAmsterdam}.
      
    \subsection{Santander smart city}
      Santander has his own sensor network testbed for environmental monitoring, outdoor parking area management, or traffic intensity monitoring.
      
      \cite{SmartcitySantander}
    
  \section{Companies}
    There are some companies that are in the business of sensor networks.
    \subsection{Smartcitizen}
      Smart Citizen\footnote{\url{http://www.smartcitizen.me/}} is platform that allows a user to buy a node based on Arduino to monitor the environment as we can see in the figure \ref{fig:SmartCitizenNode}, upload this data to their own database to anybody can see it.
      
      \begin{figure}[htbp]
        \centering
            \includegraphics[scale=0.08]{./Figures/smartcitizen.png}
            \rule{18em}{0.5pt}
        \caption[Smart Citizen Node]{Smart Citizen Node.}
        \label{fig:SmartCitizenNode}
    \end{figure}
            
    \subsection{Libelium}
      This company is an Internet of things platform provider\footnote{\url{http://www.libelium.com/}}, which supply an open source sensor platform for the Internet of things.
      They have a variety of products, here are some interesting ones:
      \begin{itemize}
        \item e-Health: A sensor shield for Arduino and Raspberry Pi for body monitoring: pulse, oxygen in blood, airflow, body temperature, electrocardiogram, glucometer, galvanic skin response, blood pressure, patient position, and muscle/eletromyography sensor. We can see the shield in the figure \ref{fig:Libeliumehealth}.
          \begin{figure}[htbp]
            \centering
                \includegraphics[scale=0.4]{./Figures/Libeliume_health.png}
                \\
                \rule{13em}{0.5pt}
            \caption[Libelium ehealth]{Libelium ehealth.}
            \label{fig:Libeliumehealth}
          \end{figure}
        
        \item Waspmote: A sensor node where we can attach more than 60 sensors, solar powered, and though for adjust into street light posts. We can see the node in the figure \ref{fig:LibeliumWaspmote}.
          \begin{figure}[htbp]
            \centering
                \includegraphics[scale=0.3]{./Figures/LibeliumWaspmote.png}
                \\
                \rule{13em}{0.5pt}
            \caption[Libelium Waspmote]{Libelium Waspmote.}
            \label{fig:LibeliumWaspmote}
         \end{figure}
       
       \item Smart Water: Is a wireless sensor platform for water quality monitoring, it also provides real-time data. We can see the node in the figure \ref{fig:LibeliumSmartWater}.
        \begin{figure}[htbp]
            \centering
                \includegraphics[scale=0.8]{./Figures/LibeliumSmartWater.png}
                \\
                \rule{13em}{0.5pt}
            \caption[Libelium Smart Water]{Libelium Smart Water.}
            \label{fig:LibeliumSmartWater}
         \end{figure}
        
      \end{itemize}     
    
  \section{Opendata services}
    The sensor networks are useless if we don't store the data, although we could save it in the device, it would be too expensive to recollect it. That is why we are going to use an opendata service:
    \subsection{Opencities}
       Opencities\cite{opencities} is a platform to browse, visualize, and download open data from different participants. They offer free space in their server, which is perfect, a very simple API to upload and download data, and a web page to visualize the stored data.
       
    \subsection{Xively}
      Xively\footnote{\url{https://xively.com}} offers an Internet of Things platform as a service, basicaly it let you stored sensor data, download it, and visualize it in graphics.
    
    \subsection{Sentilo}
      Sentilo\footnote{\url{http://www.sentilo.io}} is a open source platform for Smart Cities, it allows you to use their own service to store the data, but not many, because their goal is that anyone who wants the sentilo platform will have to installed it in their server, and then use it. It also provides a interface to show the data.
    
  \section{Sensor boards}
    In this section we discuss some of the options we could use as node.
    
    \subsection{Arduino YUN}
      The Arduino YUN is a microcontroller board with two processors as we can see in the figure \ref{fig:AYUN}, an ATmega32u4 (Arduino), and an Atheros AR9331 (For a Linux distribution named OpenWrt-Yun). It also have a Ethernet and WiFi module, a USB-A port, a micro-SD card slot, 20 digital input/ouput ping, 16 MHz crystal oscillator, 16 MHz crystal oscillator, ICSP header, and 3 reset buttons.
      \begin{figure}[htbp]
        \centering
            \includegraphics[scale=0.4]{./Figures/ArduinoYunFront_2_450px.jpg}
            \\
            \rule{15em}{0.5pt}
        \caption[Arduino YUN]{Arduino YUN.}
        \label{fig:AYUN}
      \end{figure}
      
      The great thing about the arduino YUN is that the processor for the arduino sketches can communicate with the Linux processor through the bridge library, which allows you to write python scripts and execute them. In the figure \ref{fig:BridgeInShort} we can see it.
      
      A power over ethernet module (PoE) can be attach to the arduino, which is perfect for the guifi network, as their nodes are PoE.
      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.5]{./Figures/BridgeInShort.png}
              \\
              \rule{23em}{0.5pt}
          \caption[Arduino YUN Bridge]{Arduino YUN Bridge.}
          \label{fig:BridgeInShort}
       \end{figure}
        
    \subsection{Raspberry Pi}
      Raspberry Pi\footnote{\url{http://www.raspberrypi.org/}} is a single-board computer, they have two models, A and B. The model B is more appropiate for this project because it has an Ethernet controller. It is composed by an HDMI Micro USB, and USB 2.0 connector, an SD card slot, Input/Output (GPIO) pins, an RCA connector, an audio jack, an Ethernet controller, and a Broadcom BCM2835 processor.
     
      It is very easy to attach sensors to it, and it supports Linux environment like raspbian. In the figure \ref{fig:RaspberryPiB} we can see the raspberry pi B.
      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.2]{./Figures/raspberry-pi-model-b.jpg}
              \\
              \rule{15em}{0.5pt}
          \caption[Raspberry Pi model B]{Raspberry Pi model B.}
          \label{fig:RaspberryPiB}
       \end{figure}
    
    \subsection{Picoboard}
    
      {\bf Puede que cambie Picoboard por BeagleBone}
      
      PicoBoard\footnote{\url{http://www.picocricket.com/picoboard.html}} is a board to interact with the world, it can be programmed by Scratch projects. It is less flexible than the others, it is composed by a button, a light and sound sensor, a slider, and alligator clips which can be use to build custom sensors. We can see this board in the figure \ref{fig:picoboard}.
      
      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.5]{./Figures/picoboard.jpg}
              \\
              \rule{16em}{0.5pt}
          \caption[Picoboard]{Picoboard.}
          \label{fig:picoboard}
       \end{figure}

\chapter{Technologies}
\label{Chapter3}
  
  In this chapter we focused in the techonologies used to develop this project, which are divided in four parts: arduino, sensors, python, Guifi network and opencities, and Android. 

  
  \section{Arduino vs Raspberry PI}
    For this project, we narrow down the sensor node posibilities to an Arduino Yun (Yun) or a Raspberry Pi model B (RPiB).
    
    The Yun is a microcontroller while the RPiB is a full computer, which makes it more powerful, but this project does not require too much, so both Yun and RPiB serve.
    
    The two of them had a linux environment, but with the Yun, the normal way to interact is by an arduino sketch. So RPiB will consider that you have some linux knowledge, while the Yun is better for beginners, the arduino IDE provides a variety of programs that help us to start.
    
    The sensor board is essentially the sensor node, so the size is very important, the smaller the better. In this case, the Yun is smaller. On the other hand, the sensor node will be attach on guifi nodes, which are Power over Ethernet (PoE). For the Yun there is the posibility of a PoE module which it is not available yet, but will be. The figure \ref{fig:arduinoethernetpoe} shows and arduino ethernet (similar to the Yun) with a PoE module and does not makes it bigger, and with the RPiB, the module makes it bigger, as we can see in figure \ref{fig:poerpi}.    
    %\TwoFig{./Figures/arduinoethernetpoe.jpg}{Arduino Ethernet PoE}{fig:GraphicTemperature}{./Figures/poe-rpi.jpg}{Raspberry Pi model B PoE}{fig:poerpi}
    
    \begin{figure}
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=\textwidth]{./Figures/arduinoethernetpoe.jpg}
                \caption{Arduino Ethernet PoE}
                \label{fig:arduinoethernetpoe}
        \end{subfigure}%
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=\textwidth]{./Figures/poe-rpi.jpg}
                \caption{Raspberry Pi (B) PoE}
                \label{fig:poerpi}
        \end{subfigure}
        \rule{18em}{0.5pt}
        \caption{Sensor boards}\label{fig:sensorboards}
\end{figure}

    Another advantage that YUN offers is the integrated WiFi module, since a person who does not have a guifi node can connect to one, and thus have access to opencities, and of course, to stored data.
    
    We will use the Arduino Yun instead of the Raspberry Pi basically because of the size that will become the sensor node, but if, in the future was necesary a more powerful procesor, it will be better use a Raspberry Pi.  

  \section{Sensors}
    The goal is to analyze the environment around us, for that purpose, sensors are very useful. It has been decided for the use of environmental low cost sensors that are easily accessible and usable. 
    These sensors measure the aspects that may be more useful for citizens: temperature, light, noise, humidity, and air quality.
    
    A sensor is a device which transform a physical measure to an output signal that can be read by another device, such as an arduino.
    
    In this project we will use five sensors that measured temperature, light, noise, humidity, and gas.
    
    To show how the sensors are connected to the arduino YUN I used the program fritzing\footnote{\url{http://fritzing.org/}}.
    
    \subsection{LM35: Temperature}
      LM35 [Figure \ref{fig:LM35}] is a sensor to mesure temperature, in the figure \ref{fig:TemperatureSensor_bb} we can see the way to connect it to the arduino.
      \cite{LM35}
      \TwoFig{./Figures/LM35.jpg}{LM35 sensor}{fig:LM35}{./Figures/Fritzing/TemperatureSensor_bb.png}{Temperature Sensor Breadboard}{fig:TemperatureSensor_bb}
      
    \subsection{Light Dependent Resistor (LDR)}
      LDR [Figure \ref{fig:LDR}] is a light sensor, in the figure \ref{fig:LightSensor_bb} we can see the way to connect it to the arduino.
      \TwoFig{./Figures/LDR.jpg}{LDR sensor}{fig:LDR}{./Figures/Fritzing/LightSensor_bb.png}{Light Sensor Breadboard}{fig:LightSensor_bb}
 
    \subsection{Emartee Mini Sound Sensor and Analog Sound Sensor Board Microphone MIC Controller: Noise}
      This two sensors are used to measured noise levels [Figure \ref{fig:MSS}] and [Figure \ref{fig:Analognoisesensor}]. The code to read the noise values is the same for both. In the figure \ref{fig:NoiseSensor_bb} we can see the way to connect them to the arduino.
      \cite{emarteeminisound}
      \TwoFig{./Figures/MiniSoundSensor.jpg}{Mini Sound Sensor}{fig:MSS}{./Figures/analognoisesensor.jpg}{Analog noise sensor}{fig:Analognoisesensor}      
      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.8]{./Figures/Fritzing/NoiseSensor_bb.png}
              \\
              \rule{18em}{0.5pt}
          \caption[Noise Sensor Breadboard]{Noise Sensor Breadboard.}
          \label{fig:NoiseSensor_bb}
      \end{figure}


    \subsection{Aosong DHT22 and DHT11: Humidity}
      DHT22 [Figure \ref{fig:DHT22}] and DHT11 [Figure \ref{fig:DHT11}] are humidity and temperature sensors, although we will only use the humidity measure. The output is digital, and to read it, we use an external library\footnote{\url{https://github.com/adafruit/DHT-sensor-library}}. The arduino and the humidity sensor will be connected as shown in the figure \ref{fig:HumiditySensordht22_bb}. 
      
      At the time I started the testbed, there was only 1 DHT22 sensor, so I had to use two DHT11 sensor, which change the breadboard a little bit as shown in the figure \ref{fig:HumiditySensordht11_bb}.
      \cite{dht22sensor}
      \TwoFig{./Figures/dht22.jpg}{DHT22 sensor}{fig:DHT22}{./Figures//Fritzing/HumiditySensor_bb.png}{DHT22 Breadboard}{fig:HumiditySensordht22_bb}
      \TwoFig{./Figures/dht11.png}{DHT11 sensor}{fig:DHT11}{./Figures/Fritzing/HumiditySensorDht11_bb.png}{DHT11 Breadboard}{fig:HumiditySensordht11_bb}      
      
    \subsection{MQ135: Gas sensor}
      This is a gas sensor [Figure \ref{fig:MQ135}], and we will use it to measure air quality. This sensor does not have a figure in fritzing, so I used a gas sensor that has the same output, and int the figure \ref{fig:GasSensor_bb} we can see how to connect it to the arduino.
      \TwoFig{./Figures/mq135.jpg}{MQ135 Air Quality sensor}{fig:MQ135}{./Figures/Fritzing/GasSensor_bb.png}{Gas Sensor Breadboard}{fig:GasSensor_bb}
      
      The Mq135 sensor reacts to the concentration of the following gases: NH3, NOx, alcohol, Benzene, smoke, CO2, etc.. \ref{mq135gassensor}.
      
    \subsection{BreadBoard with all the sensors}
      
      In the figure \ref{fig:AllSensors22_bb} we can see the final prototype with the DHT22 sensor, and in the figure \ref{fig:AllSensors11_bb} with the DHT11 sensor.
      
      \begin{figure}[!htbp]
          \centering
              \includegraphics[scale=0.8]{./Figures/Fritzing/AllSensors22_bb.png}
              \rule{25em}{0.5pt}
          \caption[Sensor node Prototype with DHT22]{Sensor node Prototype with DHT22.}
          \label{fig:AllSensors22_bb}
      \end{figure}
      
      \begin{figure}[!htbp]
          \centering
              \includegraphics[scale=0.8]{./Figures/Fritzing/AllSensors11_bb.png}
              \rule{25em}{0.5pt}
          \caption[Sensor node Prototype with DHT11]{Sensor node Prototype with DHT11.}
          \label{fig:AllSensors11_bb}
      \end{figure}
    
  \section{Upload sensor data}
  
    A main part of the project is upload the data from the sensors to a platform so that everyone can access them.
    
    The problem is that is needed to upload five sensor values, consequently the GeoJSON message (Explained in section \ref{GeoJSON}) takes too much memory, so the Arduino sketch can not handle it.

    For this type of operations is possible to run a script in the linux environment through the bridge library\ref{fig:BridgeInShort}.

    This being the path that is followed, there are several options for developing this script, for example, programmed in Java, C / C + +, python, etc..

    We preferred to use python because of the following reasons: fast and perfect for prototyping programming, the code is shorter and therefore, easier to understand, especially if you want to improve in the future.
    
    \subsection{GeoJSON}
    \label{GeoJSON}
      A GeoJSON\footnote{\url{http://geojson.org/}} is a format for encoding a variety of geographic data structures. The GeoJSON that we use is a collection of features, every feature contains a geometry object, in our case, a ``point'' with the longitud and latitud of the sensor node, and some properties required: ID, name, datasetID, datasetName, address, description, timestamp, value of the sensor, and unit.
      
      In the figure \ref{GeoJSON} it can be see an example of a GeoJSON message that is used in this project.
      \begin{figure}[htbp]
        \centering
            \includegraphics[scale=0.5]{./Figures/GeoJSON.png}
            \\
            \rule{15em}{0.5pt}
        \caption[GeoJSON message]{GeoJSON message.}
        \label{fig:GeoJSON}
      \end{figure}
    
  \section{Community network}
    Guifi \footnote{\url{https://www.guifi.net/}} is the network where the arduino's will be deployed, and the one providing the access to Opencities through the Internet.
    
    Guifi is a network where the people that are interested put their effort in creating an infrastructure which provides acces to the Internet at a fair price.
    
    Because of their philosophy of participation, Guifi is the perfect network for the deployment of this sensor nodes. Also their networks is large enough to become a useful sensor network, as we can see in the figure \ref{fig:Guifimap}.
    \begin{figure}[htbp]
      \centering
          \includegraphics[scale=0.5]{./Figures/Guifimap.png}
          \rule{25em}{0.5pt}
      \caption[Guifi sensor map]{Guifi sensor map.}
      \label{fig:Guifimap}
    \end{figure}
    
  \section{Storage Resource Broker}  
    Opencities\cite{opencities} is the opendata services that we have chosen, the reasons opencities has been chosen are:
    \begin{itemize}
      \item The developers are at UPF, this helps because the platform can be tested, and because they can help solve problems and make these part of the project more easy.
      \item Easy API to upload and download the data.
    \end{itemize}
    
    The role of Opencities is to be the intermediary between data creators and those who want to see them.
    In Opencities, the sensor data is uploaded into a dataset. Every user have an unique API key, and can have one or more datasets. To distinguish, the datasets have a unique ID. 
    
  \section{Visualization platform}
    
    Para la visualización de los datos de sensores hay varias opciones, una podría ser ver todos los datos en texto plano, pero resultaría dificil de entender. Otra opción es mostrar los datos en un mapa, esto puede hacerse en una página web o en una aplicación para mobiles, tablets, etc. 

Como el objetivo es que los usuarios miren la aplicación de forma eventual, lo más adecuado es usar una aplicación mobil, ya que, en estos tiempos, prácticamente todo el mundo posee un smart phone.

A partir de este paso se tiene de decidir que camino seguir para desarrollar la aplicación. Se puede hacer una aplicación directamente para el sistema operativo (iOS, Android, y Windows Phone) o bien para todos a la vez. 

Para hacer la aplicación para todas estas plataformas se tendría que hacer la aplicación en html5, css, y javascript, y mediante phonegap generar las tres aplicaciones. Pero este camino resultó demasiado dificil, y se prefirió hacer directamente una aplicación para una de las plataformas.

Una vez decidido que la aplicación será dirigida a un sistema operativo, es más optimo elegir el sistema operativo con más cuota de mercado. Por este motivo se ha elegido Android.
    
    Android is a mobile operating system from Google, it runs on smartphones, and we will use it to develop an application to see the sensor data stored in opencities, and show it to the user in a way that anybody can understand it.
    
    Nowadays everybody owns an smartphone, so the best way to make visible the sensor network is with a mobile application. There three options: Android, iOS, windows phone. Android and iOS had practically all the market, but Android has more than iOS, so Android is the right choice.
    
    This application it will be tested on a Sony Xperia Z1, with an Android 4.4.2.

\chapter{Bottom up sensor testbed}
\label{Chapter4}

  This chapter focused in the process that has been followed to complete the project, which has two main parts, the software to recollect and send the data and the Android application to show it.
  
  \section{Arduino}
    
    We will need two scripts, one to collect the data, and other to send it. This is because the memory to run an arduino sketch is very low, and the creation of the GeoJSON message to opencities is too big. That is why we use a python script called by the arduino sketch.
    
    The arduino sketch is responsible for collecting the data, write it down in a logData file, and call the python script with the collected values and an unique ID. Finally the python script have to create a GeoJSON and send it to opencities.
    
    \subsection{Collect sensor data}
    
      To collect almost all the data the skecth does not need to include any libray, except for the humidity sensors (DHT22 and DHT11) which need an external library\footnote{\url{https://github.com/adafruit/DHT-sensor-library}}.
      
      To read and write into the logData file we need the FileIO library\footnote{\url{http://arduino.cc/en/Reference/YunFileIOConstructor}}, and to call the python script we need the Process library\footnote{\url{http://arduino.cc/en/Reference/YunProcessConstructor}}.
      
      This sketch is code in a very simple way, the setup function will initialize the Bridge library to communicate with the linux environment, the Serial library for debugging purposes, and the FileSystem to log the process, and the loop function. The loop will call three functions: readSensors, readFile, and executePythonScript.
      
      \begin{itemize}
        \item {\bf readSensors:} It call 5 different functions to read every sensor, the goal of doing a separate function is to make the code more clear.
        \item {\bf readFile:} This function log the process, saves the ID of the message, the sensor values, and a timestamp.
        \item {\bf executePythonScript:} The script in python located in the SD card is in charge to create the GeoJSON with all the sensor data and upload it to opencities. This script is called by the arduino sketch.
      \end{itemize}
      
      The figure \ref{fig:Arduino sketch Flow Chart} explain how the arduino sketch works.\\
      
      \begin{figure}[htbp]
      \centering

      \begin{tikzpicture}[node distance=2cm]

        \node (bridge) [startstop] {Initialize Bridge};
        \node (Serial) [process, below of=bridge] {Initialize Serial};
        \node (FileSystem) [process, below of=Serial] {Initialize FileSystem};
        \node (ReadSensors) [process, below of=FileSystem] {Read Sensors};
        \node (ReadFile) [process, below of=ReadSensors] {Read \& Write File};
        \node (delay) [process, right of=ReadFile, xshift=2cm] {Delay of 48 seconds};
        \node (ExecutePython) [process, below of=ReadFile] {Execute Python Script};
        
        \draw [arrow] (bridge) -- (Serial);
        \draw [arrow] (Serial) -- (FileSystem);
        \draw [arrow] (FileSystem) -- (ReadSensors);
        \draw [arrow] (ReadSensors) -- (ReadFile);
        \draw [arrow] (ReadFile) -- (ExecutePython);
        \draw [arrow] (ExecutePython) -| (delay);
        \draw [arrow] (delay) |- (ReadSensors);

      \end{tikzpicture}
      \rule{35em}{0.5pt}
      \caption[Arduino sketch Flow Chart]{Arduino sketch Flow Chart.}
      \label{fig:Arduino sketch Flow Chart}
      \end{figure}
    
    \subsection{Communication with opencities}
    
      First of all, we need to create an acount in opencities, we have to follow the tutorial of the webpage\footnote{\url{http://opendata.nets.upf.edu/web/index.php/en/getting-started2}}.
      When this process is complete, we will have all the necessary information.
      
      The communication with opencities is done by a python script, to do this we need a set of libraries installed in the arduino.
      
      We need the sys and datetime library that are already installed, but the geopy, geojson, and httplib2 libraries has to be installed.
      
      This are the steps I followed to install the libraries:
      
      \begin{enumerate}
        \item First we need to configure the onboard wifi, in this website it is explained how\footnote{\url{http://arduino.cc/en/Guide/ArduinoYun}}
        \item When the YUN has an IP, now we can get into the linino by Secure Shell: 
          \\ {\centering\textbf{ssh root@X.Y.Z.W}\par}
        \item Now that we are in the linino, we begin to install the necesary packets:
          \\ {\centering
            \textbf{
              opkg update \\
              opkg install distribute \\
              opkg install python-openssl \\
              easy\_install pip \\
              pip install geojson \\
              pip install geopy \\
              pip install httplib2
            }
          \par}
      \end{enumerate}
      
      \textbf{Code explanation}
      
      With all this libraries we can communicate with opencities and store the sensor data recollected by the arduino. The \ref{fig:Python Script Flow Chart} figure explain how the python script works.\\
      
      \begin{figure}[!htbp]
      \centering

      \begin{tikzpicture}[node distance=2cm]      
        
        \node (start) [startstop] {Called by the arduino};
        \node (CorrectUsage) [decision, below of=start, yshift=-2cm] {Is the usage correct};
        \node (collectdata) [process, below of=CorrectUsage, yshift=-2cm] {Store the arguments as sensor data};
        \node (ShowCorrectWay) [process, right of=CorrectUsage, xshift=4cm] {Show the correct usage};
        \node (StopUsage) [startstop, right of=ShowCorrectWay, xshift=2cm] {Stop};
        \node (CreateGeoJSON) [process, below of=collectdata] {Create GeoJSON};
        \node (PostOpencities) [process, below of=CreateGeoJSON] {POST in Opencities};
        \node (stop) [startstop, below of=PostOpencities] {Stop};
        
        \draw [arrow] (start) -- (CorrectUsage);
        \draw [arrow] (CorrectUsage) -- node[anchor=east] {yes} (collectdata);
        \draw [arrow] (CorrectUsage) -- node[anchor=south] {no} (ShowCorrectWay);
        \draw [arrow] (ShowCorrectWay) -- (StopUsage);
        \draw [arrow] (collectdata) -- (CreateGeoJSON);
        \draw [arrow] (CreateGeoJSON) -- (PostOpencities);
        \draw [arrow] (PostOpencities) -- (stop);
        

      \end{tikzpicture}
      \rule{35em}{0.5pt}
      \caption[Python Script Flow Chart]{Python Script Flow Chart.}
      \label{fig:Python Script Flow Chart}
      \end{figure}
      
  \section{Android app}
  
    \subsection{Summary}

      To make easy to see the results of the testbed, I developed an android application. The application shows the data of the sensors in two ways, with markers that show the actual environmental value in that point, and also with heatmap points, the larger the value, the more intense the red will be. This can be seen in figure \ref{fig:App_Screenshot_3}.
      
      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.1]{./Figures/App_Screenshot_3.png}
              \\
              \rule{15em}{0.5pt}
          \caption[App Screenshot 3]{App Screenshot.}
          \label{fig:App_Screenshot_3}
      \end{figure}
      
    \subsection{Interface}
      The application interface is a unique map view where the user can zoom to a limit, go to their location, and use the top buttons. From left to right, the first button is the Marker button, the user decides whether the markers are displayed or not, and the next buttons refer to the type of sensor data to show as markers and/or as heatmap points (Temperature, Humidity, Noise, Light, and Air Quality).
      If the Marker button is checked, the user can click on the marker in the map and it will show the value of the temperature, humidity,... and the unit.
      In the figure \ref{fig:App_Screenshot_1} we can see the app with the Marker button checked, and in the figure \ref{fig:App_Screenshot_2} without.
      \TwoFig{./Figures/App_Screenshot_1.png}{App Screenshot}{fig:App_Screenshot_1}{./Figures/App_Screenshot_2.png}{App Screenshot}{fig:App_Screenshot_2}
      
    \subsection{Code}
      First of all, to create this application I have used the Google Maps Android API v2\footnote{\url{https://developers.google.com/maps/documentation/android/}} for the map view, and the Google Maps Android API utility library\footnote{\url{http://googlemaps.github.io/android-maps-utils/}} for the heatmaps. 
    
      This application has the next classes:
      \begin{itemize}
        \item MainActivity: Is the controller of the whole application.
        \item GPSTracker: Is a class to get the current location of the user.
        \item Feature, Geometry, and Properties: This are the classes where it will stored the data from the parsed JSON from opendata.
        \item DataBase: This is a singleton class where all the variables are stored, because is more easy to access from different clases.
      \end{itemize}
      
      In the figure \ref{fig:ClassDiagram1} and \ref{fig:ClassDiagram2} are the class diagram:
      
      \begin{figure}[htbp]
        \centering
          \includegraphics[page=1,scale=0.8]{./AdditionalInformation/ClassDiagram1_1.pdf}
        \rule{35em}{0.5pt}
        \caption[Class Diagram of the Android App part 1]{Class Diagram of the Android App part 1.}
        \label{fig:ClassDiagram1}
      \end{figure}
      
      \begin{figure}[htbp]
        \centering
          \includegraphics[page=1,scale=0.8]{./AdditionalInformation/ClassDiagram1_2.pdf}
        \rule{35em}{0.5pt}
        \caption[Class Diagram of the Android App part 2]{Class Diagram of the Android App part 2.}
        \label{fig:ClassDiagram2}
      \end{figure}
      
      The explanation of the code is in the following flow chart \ref{fig:Android App Flow Chart}:
      
      \begin{figure}[!htbp]
      \centering

      \begin{tikzpicture}[node distance=1cm]      
        
        \node (start) [startstop] {Initialize Google Map};
        \node (zoomlimit) [process, below of=start, yshift=-0.5cm] {Set zoom limit};
        \node (InitializeButtons) [process, below of=zoomlimit, yshift=-0.5cm] {Initialize all the Buttons and listeners};
        \node (GetCurrentLocation) [process, below of=InitializeButtons, yshift=-1cm] {Get Current Location using GPSTracker};
        \node (CallOpendata) [process, below of=GetCurrentLocation, yshift=-1cm] {Call OpenData, and parse the JSON};
        \node (CreateFeaturesByCoordinates) [process, below of=CallOpendata, yshift=-2cm] {Create a hashmap with all the features with the  coordinates as key, and a list of features for every key};
        \node (addMarkers) [process, below of=CreateFeaturesByCoordinates, yshift=-2cm] {Save only the latest features for every coordinate};
        \node (addHeatMapAndaddMakers2) [process, below of=addMarkers, yshift=-1.5cm] {Show the markers or heatmap points of a type of data};
        
        \draw [arrow] (start) -- (zoomlimit);
        \draw [arrow] (zoomlimit) -- (InitializeButtons);
        \draw [arrow] (InitializeButtons) -- (GetCurrentLocation);
        \draw [arrow] (GetCurrentLocation) -- (CallOpendata);
        \draw [arrow] (CallOpendata) -- (CreateFeaturesByCoordinates);
        \draw [arrow] (CreateFeaturesByCoordinates) -- (addMarkers);
        \draw [arrow] (addMarkers) -- (addHeatMapAndaddMakers2);
        

      \end{tikzpicture}
      \rule{35em}{0.5pt}
      \caption[Android App Flow Chart]{Android App Flow Chart.}
      \label{fig:Android App Flow Chart}
      \end{figure}
  

\chapter{Testbed results}
\label{Chapter5}

  In this chapter I will explained the procedure I followed to make this testbed, and an explanation of the results.
  
  In the figure \ref{fig:TestBed_Prototype} there is a photograph of the prototype I will use in this testbed. It is composed of an Arduino YUN, a microSD card, a breadboard, and all the sensor connected (temperature, humidity, noise, light, and gas).
  
  \begin{figure}[htbp]
      \centering
          \includegraphics[scale=0.1]{./Figures/TestBed_Prototype.JPG}
          \rule{35em}{0.5pt}
      \caption[TestBed Prototype]{TestBed Prototype.}
      \label{fig:TestBed_Prototype}
  \end{figure} 
  
  \section{Sensor node}
  
  Now, I will show the process to configure the node, part of this process is taken of the website of arduino\footnote{\url{http://arduino.cc/en/Guide/ArduinoYun}}:
  
  \subsection{Connection to the Internet}
    First of all we have to provide of Internet connection to the arduino.
    \subsubsection{Through Ethernet}
      This is the fastest way to provide of Internet connection, the arduino will behave the same way as a computer, automatically will have an IP address.
      
    \subsubsection{Through WiFi}
      This is a slowest way. The process is the following:
      \begin{enumerate}
        \item First we power the arduino YUN. 
        \item The arduino will create his own WiFi network (ArduinoYun-XXXXXXXXXXXX), and with a computer we connect to it.
        \item When we are connected to the YUN network, we go to a web browser and go to \url{http://arduino.local} or \url{192.168.240.1}. We have to put the password, which is ``arduino''. As we can see in the figure \ref{fig:YunWebPassword}.
          \begin{figure}[htbp]
            \centering
                \includegraphics[scale=0.3]{./Figures/YunWebPassword.png}
                \rule{18em}{0.5pt}
            \caption[Yun web Password]{Yun web Password.}
            \label{fig:YunWebPassword}
          \end{figure}
        
        \item The next page will be an information page, click on the configure button \ref{fig:YunWebDiagnostic}.
          \begin{figure}[htbp]
            \centering
                \includegraphics[scale=0.3]{./Figures/YunWebDiagnostic.png}
                \\
                \rule{15em}{0.5pt}
            \caption[Yun web Diagnostic]{Yun web Diagnostic.}
            \label{fig:YunWebDiagnostic}
          \end{figure}
        
        \item We will give a unique name to the Yun, and the network we want to connect \ref{fig:YunWebConfig}.
          \begin{figure}[htbp]
            \centering
                \includegraphics[scale=0.3]{./Figures/YunWebConfig.png}
                \\
                \rule{15em}{0.5pt}
            \caption[Yun web Configuration]{Yun web Configuration.}
            \label{fig:YunWebConfig}
          \end{figure}
          
        \item We press the configure \& restart button.
        \item Finally we have to connect to same network as the Yun is connected.
        
      \end{enumerate}
  \subsection{Install necessary packets}
    The arduino will run an arduino script and a python script, for the first one we do not have to install anything, but for python we will have to install some packets.
    
    To install any packet we first have to connect to the arduino (The password will be the one we entered when we configured the onboard WiFi or ``arduino''):
    
    {\begin{centering} \textbf{ssh root@X.Y.Z.W}\par \end{centering}}
    
    Now we can install all the necessary packets:
     
      {\begin{centering} \textbf{
          opkg update \\
          opkg install distribute \\
          opkg install python-openssl \\
          easy\_install pip \\
          pip install geojson \\
          pip install geopy \\
          pip install httplib2
        }
      \par \end{centering}}
    
  \subsection{Copy the scripts}
    First of all we have to create the some directories, so once we make the ssh command, go to ``/mnt/sda1'', make the following comands:
    
    {\begin{centering} \textbf{
    mkdir arduino \\
    cd arduino \\
    mkdir www \\
    }\par \end{centering}}
    
    We have to copy the python script ``main.py'' into the SD-Card. We have two ways to do this, put the SDCard into a computer an save the files in there, or we can copy the files into the arduino through the network with the following comand:
    
    {\begin{centering} \textbf{
    scp main.py root@192.168.2.149:/mnt/sda1/arduino/www/main.py
    }\par \end{centering}}
  
  \subsection{Attach the sensors}
    Now that we have the python step done, we have to attach the sensors to the arduino Yun, to do that look at figure \ref{fig:AllSensors22_bb} or figure \ref{fig:AllSensors11_bb}.
    
    \subsubsection{Prototype}
      At the end of this project I used a proto shield instead of a breadboard to create a real prototype.
  
  \subsection{Arduino Code}
    To upload an arduino sketch to the yun we have to use the following IDE: arduino 1.5.5. There are two ways to upload an sketch, through a USB cable connected to the arduino, or through the Internet, if we are in the same network as the arduino, it will appear in the IDE.
  
  \section{Actual Testbed}
    We have three arduino, so we have to mount the sensor node and put them in three different places in free space but being sure it will not get wet.
    
    When we have decided when we are going to put them, we have to introduce manually the location and the unique ID into the python script. We can do that by entering into the arduino by secure shell as we did earlier, go to the folder where the ``main.py'' is, and modified the following line by using ``nano'':
    
    {\begin{centering} \textbf{self.address = 'Sagrada Familia, Carrer de Mallorca, Barcelona'}\par \end{centering}}
    
    After a day of collecting data, we will get the arduino's back, take the three logData files, and show the data into some graphics.
    
    In the figure \ref{fig:Testbedmap} there are the nodes deployed, the location try to be a little bit different to get distinc values.
    \begin{figure}[htbp]
      \centering
          \includegraphics[scale=0.2]{./Figures/Testbedmap.png}
          \\
          \rule{15em}{0.5pt}
      \caption[Testbed Map]{Testbed Map.}
      \label{fig:Testbedmap}
    \end{figure}
    
    \subsection{Results}
      In the next figures: \ref{fig:GraphicTemperature}, \ref{fig:GraphicLight}, \ref{fig:GraphicNoise}, \ref{fig:GraphicHumidity}, \ref{fig:GraphicGas}, there are some graphics of the testbed. It can be seen that the node in Montgat, near the sea, the humidity is bigger, on the other hand, the noise is lower than the one in Glorias.
      
      This graphics had been done with an octave script that analyze the logData file in every sensor node.
      
      \TwoFig{./Figures/GraphicTemperature.png}{Graphic Temperature}{fig:GraphicTemperature}{./Figures/GraphicLight.png}{Graphic Light}{fig:GraphicLight}
      
      \TwoFig{./Figures/GraphicNoise.png}{Graphic Noise}{fig:GraphicNoise}{./Figures/GraphicHumidity.png}{Graphic Humidity}{fig:GraphicHumidity}
      
      \begin{figure}[htbp]
        \centering
            \includegraphics[scale=0.5]{./Figures/GraphicGas.png}
            \\
            \rule{15em}{0.5pt}
        \caption[Graphic Air Quality]{Graphic Air Quality.}
        \label{fig:GraphicGas}
      \end{figure}
    
\chapter{Conclusions}
\label{Chapter6}
  
  During this project we analyzed, developed, and deployed sensor nodes into an open network, the inicials goals of the pilot.
  
  It is clear, therefore, that to deploy a sensor network, like the one explained in the previous chapter, is necessary a bit of knowledge about sensors, arduino, and linux. 
  
  The testbed shows that the nodes worked perfectly, so, in terms of scalability, the problem could be in opencities or in the Android App. Opencities proved work perfectly, but the Android App came out with a problem, it downloads all the data from opencities, so it takes a little bit of time to be ready.
  
  In conclusion, the project satisfies the goals presented at the start, which are share sensor data on an open network, and let the users visualize it.

\chapter{Future work}
\label{Chapter7}
  
  This project have three ways of improvement:
    \begin{enumerate}
      \item {\bf Sensor node:} Make a final prototype trying to reduce the size to make it the smaller the better, and attach the power over ethernet module.
      \item {\bf Opencities:} It is a platform that can improved in many ways, starting with the way to create a dataset, which can be confusing, to the presentation of the data.
      \item {\bf Android App:} It showed some problems when there is a lot of data to download, so it should be improved to download only the data that is going to show. Also it could show the data of the whole day and let the user see the changes. 
    \end{enumerate}

\bibliography{bibliography}
\phantomsection
\addcontentsline{toc}{chapter}{BIBLIOGRAPHY}
\cleardoublepage

\chapter{Appendixes}
\label{Chapter8}

  \input{./Appendix/Pilot_Charter.tex}
  \input{./Appendix/Planning_Report.tex}


\backmatter
\printindex





\end{document}


%NUMERACIÓ DE LA PÀGINA EXTERIOR EXCEPTE EN LA PRIMERA PÀGINA DE CADA CAPÍTOL
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyfoot{}
\fancyfoot[RO]{\thepage}
\fancyfoot[LE]{\thepage}


%MUTIPLES ÍNDEX
%En el preàmbul
\usepackage{multind}
\makeindex{authors}
%Introducció d'entrades la forma
\index{authors}{Einstein}
%Situació de l'Índex
\printindex{authors}{Author index}
%Cal eliminar les comandes \usepakage{makeidx} \makeindex \printindex
%cal exacutar des de la línia de comandes makeindex authors

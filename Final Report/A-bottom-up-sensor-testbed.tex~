\documentclass[12pt, a4paper,twoside]{tesi_upf}
\usepackage{pgfgantt}
\usepackage{tikz}


\usetikzlibrary{shapes.geometric, arrows}

\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!30]

\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!30]

\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, text width=3cm, draw=black, fill=orange!30]

\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]

\tikzstyle{arrow} = [thick,->,>=stealth]

%CODIFICACIÓ
\usepackage[latin1]{inputenc}


%IDIOMES
\usepackage[catalan,english]{babel}

%NOMÉS PER A OBTENIR INDICACIÓ DEL MARC EN MIDA A4
\usepackage[cam,a4,center,frame]{crop}

%PER A INCLOURE GRÀFICS I EL LOGO DE LA UPF
\usepackage{graphicx}
\usepackage{caption}
\usepackage{acronym}
\usepackage{multirow}
%FONTS TIMES O GARAMOND, 
\usepackage{times}
%\usepackage{garamond}
\usepackage{url}

\usepackage{pdfpages}
%SENSE HEADINGS: NO MODIFICAR
\pagestyle{plain}

%PER A L'ÍNDEX DE MATÈRIES
\usepackage{makeidx}
\makeindex

%ESTIL DE BIBLIOGRAFIA
\bibliographystyle{apalike}


%AQUEST DOCUMENT ÉS EN CATALÀ
\selectlanguage{english}

%EN COMPTES DE ÍNDEX, LA TAULA DE CONTINGUTS ES TITULA SUMARI
\addto\captionscatalan
  {\renewcommand{\contentsname}{\Large \sffamily Sumari}}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~
% CUSTOM PACKAGES
% ~~~~~~~~~~~~~~~~~~~~~~~~~~
\usepackage{hyperref}
\usepackage{titlesec}
\setcounter{secnumdepth}{4}
\usepackage{pdfpages}

%AFEGIU EN AQUESTA PART LES VOSTRES DADES
\title{A bottom up sensor testbed}
\author{Sergio Almendros Díaz}
\thyear{2013}
\department{Departament de Tecnologies de la Informació i les Comunicacions (DTIC)}
\supervisor{Jaume Barceló}


\begin{document}

\pdfstringdefDisableCommands{%
\let\MakeUppercase\relax
}

\frontmatter

\maketitle

\cleardoublepage


%%%%%% Dedicatòria; si no es vol posar, comenteu fins a final de dedicatòria

\noindent Dedicatòria

\cleardoublepage

%%%%%% Final de dedicatòria


%%%%%% Agraïments; si no es vol posar, comenteu fins a final de agraïments
\noindent {\Large \sffamily Acknowledgments}
\\[12pt] 
 
Acknowledgments

\cleardoublepage

%%%%%% Final dels agraïments

%ABSTRACT EN DOS IDIOMES. COM A MÍNIM CATALÀ. SI L'ALTRE ÉS EN CASTELLA CANVIEU EL QUE POSA ABSTRACT
\selectlanguage{english}
\section*{\Large \sffamily Abstract}

A bottom up sensor testbed is a sensor platform which collect sensory data. In this thesis we will develop a sensor platform that can be attached to guifi nodes to gather and share sensory data throught the guifi network and opencities.
Guifi is an open network built to everyone can join it providing his own connection and opencities is a platform developed in UPF which allows any user to upload and download sensory data.\\
For the guifi nodes we will use an Arduino YUN (Arduino is an open-source electronics prototyping platform) which will gathered the sensory data and send it to opencities, then an Android application will get and visualize this data.
\\
This solution will show how to create a sensor platform and see the result very quickly which could help to other developers build their own platform to share sensory data.


\selectlanguage{catalan}
\vspace*{\fill}
\section*{\Large \sffamily  Resum}

Un banc de proves de sensors de baix a dalt és una plataforma de sensors que recull dades de sensors. En aquesta tesi es desenvoluparà una plataforma de sensors que es pot conectar a nodes guifi per recopilar i compartir dades de sensors a través de la xarxa guifi i opencities. 
Guifi és una xarxa oberta construïda per a tothom pot unir-se a ella proporcionant la seva pròpia connexió i opencities és una plataforma desenvolupada a la UPF, que permet a qualsevol usuari pujar i descarregar dades sensorials. \\ 
Per als nodes guifi utilitzarem un Arduino YUN (Arduino és una plataforma de creació de prototips electrònics de codi obert) per reunir les dades de sensors i enviar-les a openities, i a continuació, una aplicació per Android descarregarà i visualitzarà aquestes dades. 
\\
Aquesta solució mostrarà com crear una plataforma de sensors i veure el resultat molt ràpid, el que podria ajudar a altres desenvolupadors a construir la seva pròpia plataforma per compartir dades de sensors.

\vspace*{\fill}

\selectlanguage{english}
\cleardoublepage
%FIN DE ABSTRACTE

%PREFACI OPCIONAL. SI NO ES VOL, COMENTEU FINS EL FINAL DE PREFACI
%{\bf Prefaci}
%
%\cleardoublepage
%FINAL DE PREFACI


%TAULA DE CONTINGUTS: OBLIGATÒRIA
\selectlanguage{english}
\tableofcontents

%INDEX DE FIGURES; NOMÉS ES POSA SI HI HA FIGURES
\listoffigures
%Fa que aparegui al sumari
\addcontentsline{toc}{chapter}{List of figures}

%INDEX DE TAULES; NOMÉS ES POSA SI HI HA TAULES
\listoftables
%Fa que aparegui al sumari
\addcontentsline{toc}{chapter}{List of tables}


%COMENÇA EL TEXT
\mainmatter
\chapter{Introduction}
\label{Chapter1}

The development of this project involves two parts, recollect data from sensors with the arduino and send it to opencities, there is when we will make the sensor testbed, and download the data from an Android Application to show it.

A sensor testbed is a small sensor network which has the goal to gather data, and test the technologies used as nodes to see if they are the best options to create a real one.

Bottom-up is, basically, the pattern that we used to build the sensor testbed, where the end users, in this case, guifi.net users, are the ones who have to assemble the sensor nodes and attached them to the guifi nodes to create the sensor network. With the bottom-up model, the data is provide and use by the end users, which prevents big companies or government to hide this information.
 
This project is an easy way to understand the importance of sensor networks and how they can help us to know, for example, if there is low quality air in our city, and do something about it.

As sensor nodes we will use an Arduino YUN, Arduino is an open-source electronics prototyping platform, that allows the user to obtain analog reads from a sensor very easily and, with a Power over Ethernet module, it can be attached to guifi nodes and send the sensory data to a sensor platform, like opencities. 

When the sensory data is stored, we will develop an Android application to visualize this data and make it more accessible to other users not involved with guifi.net.

In the following chapters I will explain the state of sensor networks nowadays \ref{Chapter2}, which technologies we will use \ref{Chapter3}, and how the project has been done, as well as all the problems found during the process \ref{Chapter4}. 

The final goal of the project is to build a sensor testbed and there will be the results \ref{Chapter5}, and, to finish, the conclusions \ref{Chapter6} and the future work \ref{Chapter7}.
  
\chapter{State of the Art}
\label{Chapter2}
  
  \section{Introduction}
    Sensor networks started as a mecanism of defense develop by the military during the Cold War, with acoustic sensors they try to find Soviet submarines. But, this rearch continue at universities, trying to make this sensors smaller, and with the posibility of real-time data\cite{chong2003sensor}.
    
    Right now, the sensors are small enough, and the processors with network technology consume low energy, which allows us to deploy a test bed without bothering the people around it.
    
    Smart cities are the next step, a city capable of having real-time information, not only about the environment, it can go from the amount of cars that pass a road, to the amount of rain water in a day. This kind of information help to manage more efficiently the city.
    
    It is important to share this information, in the case that the government build the sensor network, the data should be open to everyone can see it. There are already some sensor networks functioning, some of them are from the government, and, sometimes, there are not that open about their data, but there are also some people who have sensor in his home and share their sensory data with anyone who wants to see it.

  \section{Sensor networks and smart cities}
    In this section we introduce a few projects of sensor networks that cities deployed:
    
    \subsection{Amsterdam smart city}
      Amsterdam have a lot of projects concerning the smart city concept, like the "Flexible street lighting", which allows the government to monitor the street and switch off the lights saving energy, or the "Smart parking" which let drivers to know if there are free spots to park, and, in consecuence, reduce air pollution\cite{SmartcityAmsterdam}.
      
    \subsection{Santander smart city}
      Santander has his own sensor network testbed for environmental monitoring, outdoor parking area management, or traffic intensity monitoring\cite{SmartcitySantander}.
    
    
  \section{Companies}
    There are some companies that are in the business of sensor networks, such as "Schneider Electric", a multinational company that produces components for energy management, or smartcitizen, a platform that allows a user to have a sensor node and share the data with everyone.

    
  \section{Opendata services}
    The sensor networks are useless if we don't store the data, although we could save it in the device, it would be too expensive to recollect it, so we chose a web opendata service, which is a website that allows the user to upload and download the data with an open API, and normally they have some way to visualize it.
    
    There are some services such as Xively, o sentilo which allows you to install it in your server, and opencities, an opendata service developed in the Pompeu Fabra University.
    
    

\chapter{Technologies}
\label{Chapter3}
  
  In this chapter we focused in the techonologies used to develop this project, which is divided in four parts: arduino, sensors, python, Guifi network and opencities, and Android. 

  
  \section{Arduino}
    The Arduino board that we use is an arduino YUN\footnote{\url{http://arduino.cc/en/Main/ArduinoBoardYun?from=Main.ArduinoYUN}}, which support a Linux distribution based on OpenWRT named Linino, and it has Ethernet and wifi suport, and a micro-SD card slot, those are basically the reason why we decided to use it, as we have to store the recollected data, and send it to opencities.
    
    We also have planned to attached a power over ethernet (PoE) module because the arduino's will be attached to guifi nodes which are also PoE.
    
    \begin{figure}[htbp]
        \centering
            \includegraphics[scale=0.5]{./Figures/ArduinoYunFront_2_450px.jpg}
            \rule{18em}{0.5pt}
        \caption[Arduino YUN]{Arduino YUN.}
        \label{fig:AYUN}
    \end{figure}

  \section{Sensors}
    A sensor is a device which transform a physical measure to an output signal that can be read by another device, such as an arduino, 
    
    In this project we will use five sensors that measured temperature, light, noise, humidity, and air quality.
    
    To show how the sensors are connected to the arduino YUN I used the program fritzing\footnote{\url{http://fritzing.org/}}.
    
    \subsection{LM35: Temperature}
      LM35 is a sensor with an output voltage proportional to the Centigrade temperature, the output pin goes directly to an analog pin in the arduino \ref{fig:LM35} as shown in the figure \ref{fig:TemperatureSensor_bb}.

      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.5]{./Figures/LM35.jpg}
              \rule{25em}{0.5pt}
          \caption[LM35 sensor]{LM35 temperature sensor.}
          \label{fig:LM35}
      \end{figure}
      
      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=1]{./Figures/Fritzing/TemperatureSensor_bb.png}
              \rule{25em}{0.5pt}
          \caption[Temperature Sensor Breadboard]{Temperature Sensor Breadboard.}
          \label{fig:TemperatureSensor_bb}
      \end{figure}
      
    \subsection{Light Dependent Resistor (LDR)}
      The LDR\ref{fig:LDR} is a light sensor that where is connected to an arduino, as shown in the figure \ref{fig:LightSensor_bb}, returns a value between 0 to 1024 depending on the light.

      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.3]{./Figures/LDR.jpg}
              \rule{25em}{0.5pt}
          \caption[LDR sensor]{photoresistor or light-dependent resistor.}
          \label{fig:LDR}
      \end{figure}
      
      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=1]{./Figures/Fritzing/LightSensor_bb.png}
              \rule{25em}{0.5pt}
          \caption[Light Sensor Breadboard]{Light Sensor Breadboard.}
          \label{fig:LightSensor_bb}
      \end{figure}
 
    \subsection{Emartee Mini Sound Sensor: Noise}
      This sensor is used to measured noise levels \ref{fig:MSS}, which is similar to the LM35 in the connexion, the output pin goes directly to an analgo pin as shown in the figure \ref{fig:NoiseSensor_bb}, but I did not find a figure for this sensor, so I put a microphone that has the same pins.

      \begin{figure}[!htbp]
          \centering
              \includegraphics[scale=0.5]{./Figures/MiniSoundSensor.jpg}
              \rule{25em}{0.5pt}
          \caption[Mini Sound Sensor]{Mini Sound Sensor.}
          \label{fig:MSS}
      \end{figure}
      
      \begin{figure}[!htbp]
          \centering
              \includegraphics[scale=1]{./Figures/Fritzing/NoiseSensor_bb.png}
              \rule{25em}{0.5pt}
          \caption[Noise Sensor Breadboard]{Noise Sensor Breadboard.}
          \label{fig:NoiseSensor_bb}
      \end{figure}
      
    \subsection{Aosong DHT22: Humidity}
      DHT22 is a humidity and temperature sensor, although we will only use the humidity measure. The output is digital, and to read it, we use an external library already developed \ref{fig:DHT22}. The arduino and the humidity sensor will be connected as shown in the figure \ref{fig:HumiditySensor_bb}.

      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.5]{./Figures/dht22.jpg}
              \rule{25em}{0.5pt}
          \caption[DHT22 sensor]{DHT22 humidity and temperature sensor.}
          \label{fig:DHT22}
      \end{figure}
      
      \begin{figure}[!htbp]
          \centering
              \includegraphics[scale=1]{./Figures/Fritzing/HumiditySensor_bb.png}
              \rule{25em}{0.5pt}
          \caption[Humidity Sensor Breadboard]{Humidity Sensor Breadboard.}
          \label{fig:HumiditySensor_bb}
      \end{figure}
      
    \subsection{MQ135: Air Quality}
      This sensor is gas sensor, and we will use it to measured air quality. In this webpage\footnote{\url{http://arduino-info.wikispaces.com/Air-Gas-Sensors}} explain how to connect the sensor to the arduino, but the one that I bought has three pins joined in one, which make it easier \ref{fig:MQ135}, but this has no figure in fritzing, so I used a gas sensor that has the same output, and the resutl is in the figure \ref{fig:AirQualitySensor_bb}.
      
      The previous sensors are more similar, but this one can be used to measure the environment by the citizens and, it can be used to control the gas in a factory for example.

      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.3]{./Figures/mq135.jpg}
              \rule{25em}{0.5pt}
          \caption[MQ135]{MQ135 Air Quality sensor.}
          \label{fig:MQ135}
      \end{figure}
      
      \begin{figure}[!htbp]
          \centering
              \includegraphics[scale=1]{./Figures/Fritzing/AirQualitySensor_bb.png}
              \rule{25em}{0.5pt}
          \caption[Air Quality Sensor Breadboard]{Air Quality Sensor Breadboard.}
          \label{fig:AirQualitySensor_bb}
      \end{figure}
      
    \subsection{BreadBoard with all the sensors}
      
      This \ref{fig:AllSensors_bb} is the final prototype of the arduino YUN and all the sensors connected to it.
      
      \begin{figure}[!htbp]
          \centering
              \includegraphics[scale=0.8]{./Figures/Fritzing/AllSensors_bb.png}
              \rule{25em}{0.5pt}
          \caption[Breadboard of all the sensors connected to the Arduino YUN]{Breadboard of all the sensors connected to the Arduino YUN.}
          \label{fig:AllSensors_bb}
      \end{figure}
    
  \section{Python}
    Because of the low memory for the arduino sketches, we have to use a python script to communicate with opencities. The python installed in the arduino is the python 4.2.5. 
    
  \section{Guifi network and opencities}
    Guifi network\footnote{\url{https://www.guifi.net/}} is the network where the arduino's will be installed, and the one which will provide the access opencities through the Internet.
    
    Opencities\footnote{\url{http://opencities.upf.edu/web/index.php/en/}} is the opendata services that we have chosen, the strengths of opencities are that give us free storage, a great and easy API to upload and download the data, and, also, the developers are in the UPF and problems will be solved more easily.
    
  \section{Android}
    Android is an open source mobile operating system from Google, it runs on smartphones, and we will use this OS to develop an application to see the sensory data stored in opencities, and show it to the user in a way that anybody can understand the values.
    
    This application it will be tested on a Sony Xperia Z1, with an Android 4.3.

\chapter{Bottom up sensor testbed}
\label{Chapter4}

  This chapter focused in the process that it is been followed to complet the project, which has two main parts, the software to recollect and send the sensory data and the Android application to show it.
  
  \section{Arduino Code}
    
    The arduino YUN will run only one file, CollectAndSendData.ino, but the arduino sketches are executed with a very low memory, so we need to use a python script which will run in the linino.
    
    To get started with how the arduino YUN visit this website\footnote{\url{http://arduino.cc/en/Guide/ArduinoYun}}.
    
    The arduino sketch is responsible for collecting the data, write it down in the logData file, and call the python script with the collected values and an unique ID, and the python script create the GeoJSON and send it to opencities.
    
    \subsection{Collect sensory data}
    
      To collect almost all the data the skecth does not need to include any libray because it is read by the analog read, except for the humidity sensor (DHT22) which need an external library.
      
      To read and write into the logData file the FileIO library\footnote{\url{http://arduino.cc/en/Reference/YunFileIOConstructor}} is needed, and to call the python script we need the Process library\footnote{\url{http://arduino.cc/en/Reference/YunProcessConstructor}}.
      
      The figure \ref{fig:Arduino sketch Flow Chart} explain how the arduino sketch works, but because is a process a little bit long, a more specific explanation will be in the appendix:\\
      
      \begin{figure}[htbp]
      \centering

      \begin{tikzpicture}[node distance=2cm]

        \node (bridge) [startstop] {Initialize Bridge};
        \node (Serial) [process, below of=bridge] {Initialize Serial};
        \node (FileSystem) [process, below of=Serial] {Initialize FileSystem};
        \node (ReadSensors) [process, below of=FileSystem] {Read Sensors};
        \node (ReadFile) [process, below of=ReadSensors] {Read \& Write File};
        \node (delay) [process, right of=ReadFile, xshift=2cm] {Delay of 5 seconds};
        \node (ExecutePython) [process, below of=ReadFile] {Execute Python Script};
        
        \draw [arrow] (bridge) -- (Serial);
        \draw [arrow] (Serial) -- (FileSystem);
        \draw [arrow] (FileSystem) -- (ReadSensors);
        \draw [arrow] (ReadSensors) -- (ReadFile);
        \draw [arrow] (ReadFile) -- (ExecutePython);
        \draw [arrow] (ExecutePython) -| (delay);
        \draw [arrow] (delay) |- (ReadSensors);

      \end{tikzpicture}
      \rule{35em}{0.5pt}
      \caption[Arduino sketch Flow Chart]{Arduino sketch Flow Chart.}
      \label{fig:Arduino sketch Flow Chart}
      \end{figure}


    
    \subsection{Communication with opencities}
    
      The communication with opencities is done by a python script, to do this a set of libraries are needed and there are some which have to be installed in the linino.
      
      We need the sys and datetime library that are already installed, but we need the geopy library to get the latitud and longitude that will be include in the geojson, to do that we need the geojson library. To post the sensory data into opencities we use the httplib2.
      
      Now all the steps to install the libraries mentioned above are explained:
      
      \begin{enumerate}
        \item First we need to configure the onboard wifi, in this website it is explained how\footnote{\url{http://arduino.cc/en/Guide/ArduinoYun}}
        \item When the YUN have an IP, now we can get into the linino by Secure Shell: 
          \\ {\centering\textbf{ssh root@X.Y.Z.W}\par}
        \item Now that we are in the linino, we begin to install the necesary packets:
          \\ {\centering
            \textbf{
              opkg update \\
              opkg install distribute \\
              opkg install python-openssl \\
              easy\_install pip \\
              pip install geojson \\
              pip install geopy \\
              pip install httplib2
            }
          \par}
      \end{enumerate}
      
      With all this libraries we can communicate with opencities and store the sensory data recollected by the arduino. The \ref{fig:Python Script Flow Chart} figure explain how the arduino sketch works, but because is a process a little bit long, a more specific explanation will be in the appendix:\\
      
      \begin{figure}[!htbp]
      \centering

      \begin{tikzpicture}[node distance=2cm]      
        
        \node (start) [startstop] {Called by the arduino};
        \node (CorrectUsage) [decision, below of=start, yshift=-2cm] {Is the usage correct};
        \node (collectdata) [process, below of=CorrectUsage, yshift=-2cm] {Store the arguments as sensory data};
        \node (ShowCorrectWay) [process, right of=CorrectUsage, xshift=4cm] {Show the correct usage};
        \node (StopUsage) [startstop, right of=ShowCorrectWay, xshift=2cm] {Stop};
        \node (CreateGeoJSON) [process, below of=collectdata] {Create GeoJSON};
        \node (PostOpencities) [process, below of=CreateGeoJSON] {POST in Opencities};
        \node (stop) [startstop, below of=PostOpencities] {Stop};
        
        \draw [arrow] (start) -- (CorrectUsage);
        \draw [arrow] (CorrectUsage) -- node[anchor=east] {yes} (collectdata);
        \draw [arrow] (CorrectUsage) -- node[anchor=south] {no} (ShowCorrectWay);
        \draw [arrow] (ShowCorrectWay) -- (StopUsage);
        \draw [arrow] (collectdata) -- (CreateGeoJSON);
        \draw [arrow] (CreateGeoJSON) -- (PostOpencities);
        \draw [arrow] (PostOpencities) -- (stop);
        

      \end{tikzpicture}
      \rule{35em}{0.5pt}
      \caption[Python Script Flow Chart]{Python Script Flow Chart.}
      \label{fig:Python Script Flow Chart}
      \end{figure}
      
  \section{Android app}
  
    \subsection{Summary}

      To make easy to see the results of the testbed, I created an android application for the purpose of visualize them. The application shows the data of the sensors in two ways, with markers which will show the actual value of the temperature or noise in that point, and, also, with heatmap points, the larger the value of the temperature or noise, the more intense the red will be. This can be seen in figure \ref{fig:App_Screenshot_3}.
      
      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.1]{./Figures/App_Screenshot_3.png}
              \rule{35em}{0.5pt}
          \caption[App Screenshot 3]{App Screenshot 3.}
          \label{fig:App_Screenshot_3}
      \end{figure}
      
    \subsection{Interface}
      The application interface is a unique map view, where the user can zoom to a limit, go to their location, and, use the top buttons. From left to right, the first button is the Marker button, the user decides whether the markers are displayed or not, and the next buttons refer to the type of data sensor which is shown as markers and as heatmap points (Temperature, Humidity, Noise, Light, and Air Quality).
      If the Marker button is checked, the user can click on the marker in the map and it will show the value of the temperature, humidity,... and the unit.
      In the figure \ref{fig:App_Screenshot_1} we can see the app with the Marker button checked, and in the figure \ref{fig:App_Screenshot_2} without.
      
      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.1]{./Figures/App_Screenshot_1.png}
              \rule{35em}{0.5pt}
          \caption[App Screenshot 1]{App Screenshot 1.}
          \label{fig:App_Screenshot_1}
      \end{figure}
      
      \begin{figure}[htbp]
          \centering
              \includegraphics[scale=0.1]{./Figures/App_Screenshot_2.png}
              \rule{35em}{0.5pt}
          \caption[App Screenshot 2]{App Screenshot 2.}
          \label{fig:App_Screenshot_2}
      \end{figure}
      
    \subsection{Code}
      First of all, to create this application I have used the Google Maps Android API v2\footnote{\url{https://developers.google.com/maps/documentation/android/}} for the map view, and the Google Maps Android API utility library\footnote{\url{http://googlemaps.github.io/android-maps-utils/}} for the heatmaps. 
    
      This application has the next classes, in the next figure \ref{} is the class diagram:
      \begin{itemize}
        \item MainActivity: Is the controller of the whole application.
        \item GPSTracker: Is a class to get the current location of the user.
        \item Feature, Geometry, and Properties: This are the classes where it will stored the data from the parsed JSON from opendata.
        \item DataBase: This is a singleton class where all the variables are stored, because is more easy to access from different clases.
      \end{itemize}
      
      \begin{figure}[htbp]
        \centering
        \includegraphics[page=1,scale=0.65]{./AdditionalInformation/ClassDiagram1_1.pdf}
        \rule{35em}{0.5pt}
        \caption[Class Diagram of the Android App part 1]{Class Diagram of the Android App part 1.}
        \label{fig:ClassDiagram1}
      \end{figure}
      
      \begin{figure}[htbp]
        \centering
        \includegraphics[page=1,scale=0.65]{./AdditionalInformation/ClassDiagram1_2.pdf}
        \rule{35em}{0.5pt}
        \caption[Class Diagram of the Android App part 2]{Class Diagram of the Android App part 2.}
        \label{fig:ClassDiagram2}
      \end{figure}
      
      The explanation of the code will be in the following flow chart \ref{fig:Android App Flow Chart}:
      
      \begin{figure}[!htbp]
      \centering

      \begin{tikzpicture}[node distance=1cm]      
        
        \node (start) [startstop] {Initialize Google Map};
        \node (zoomlimit) [process, below of=start, yshift=-0.5cm] {Set zoom limit};
        \node (InitializeButtons) [process, below of=zoomlimit, yshift=-0.5cm] {Initialize all the Buttons and listeners};
        \node (GetCurrentLocation) [process, below of=InitializeButtons, yshift=-1cm] {Get Current Location using GPSTracker};
        \node (CallOpendata) [process, below of=GetCurrentLocation, yshift=-1cm] {Call OpenData, and parse the JSON};
        \node (CreateFeaturesByCoordinates) [process, below of=CallOpendata, yshift=-2cm] {Create a hashmap with all the features with the  coordinates as key, and a list of features for every key};
        \node (addMarkers) [process, below of=CreateFeaturesByCoordinates, yshift=-2cm] {Save only the latest features for every coordinate};
        \node (addHeatMapAndaddMakers2) [process, below of=addMarkers, yshift=-1.5cm] {Show the markers or heatmap points of a type of data};
        
        \draw [arrow] (start) -- (zoomlimit);
        \draw [arrow] (zoomlimit) -- (InitializeButtons);
        \draw [arrow] (InitializeButtons) -- (GetCurrentLocation);
        \draw [arrow] (GetCurrentLocation) -- (CallOpendata);
        \draw [arrow] (CallOpendata) -- (CreateFeaturesByCoordinates);
        \draw [arrow] (CreateFeaturesByCoordinates) -- (addMarkers);
        \draw [arrow] (addMarkers) -- (addHeatMapAndaddMakers2);
        

      \end{tikzpicture}
      \rule{35em}{0.5pt}
      \caption[Android App Flow Chart]{Android App Flow Chart.}
      \label{fig:Android App Flow Chart}
      \end{figure}
  

\chapter{Testbed results}
\label{Chapter5}

\chapter{Conclusions}
\label{Chapter6}

\chapter{Future work}
\label{Chapter7}

\chapter{Appendixes}
\label{Chapter8}

  \section{Pilot Charter}
  \section{Documentation}


\bibliography{bibliography}
\cleardoublepage



\backmatter
\printindex





\end{document}


%NUMERACIÓ DE LA PÀGINA EXTERIOR EXCEPTE EN LA PRIMERA PÀGINA DE CADA CAPÍTOL
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyfoot{}
\fancyfoot[RO]{\thepage}
\fancyfoot[LE]{\thepage}


%MUTIPLES ÍNDEX
%En el preàmbul
\usepackage{multind}
\makeindex{authors}
%Introducció d'entrades la forma
\index{authors}{Einstein}
%Situació de l'Índex
\printindex{authors}{Author index}
%Cal eliminar les comandes \usepakage{makeidx} \makeindex \printindex
%cal exacutar des de la línia de comandes makeindex authors
